<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>destination_based_sales.bea API documentation</title>
<meta name="description" content="This module is used to load and preprocess data from the Bureau of Economic Analysis (BEA). These allow to split revenue
variables between sales â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>destination_based_sales.bea</code></h1>
</header>
<section id="section-intro">
<p>This module is used to load and preprocess data from the Bureau of Economic Analysis (BEA). These allow to split revenue
variables between sales directed to the host (or affiliate) country, to the US and to any third country. Data are loaded
from Excel files saved in the "data" folder.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module is used to load and preprocess data from the Bureau of Economic Analysis (BEA). These allow to split revenue
variables between sales directed to the host (or affiliate) country, to the US and to any third country. Data are loaded
from Excel files saved in the &#34;data&#34; folder.
&#34;&#34;&#34;


########################################################################################################################
# --- Imports

import os

import numpy as np
import pandas as pd

from destination_based_sales.utils import CODES_TO_IMPUTE_BEA, impute_missing_codes


########################################################################################################################
# --- Diverse

path_to_dir = os.path.dirname(os.path.abspath(__file__))

path_to_geographies = os.path.join(path_to_dir, &#39;data&#39;, &#39;geographies.csv&#39;)


########################################################################################################################
# --- Content

class BEADataPreprocessor:

    def __init__(
        self,
        year,
        path_to_dir=path_to_dir,
        path_to_geo_file=path_to_geographies
    ):
        &#34;&#34;&#34;
        The instructions allowing to load and preprocess BEA data are organised in a Python class, BEADataPreprocessor.

        This is the instantiation function for this class. It requires several arguments:

        - the year to consider (for now, one of 2016, 2017 or 2018);
        - the path to the directory where this Python file is located, to retrieve the appropriate data file;
        - the path to the &#34;geographies.csv&#34; file, used for instance to complement BEA data with country codes.
        &#34;&#34;&#34;
        self.year = year

        # We construct the path to the relevant data file, which depends on the year considered
        self.path_to_bea = os.path.join(
            path_to_dir,
            &#39;data&#39;,
            str(year),
            &#39;Part-II-E1-E17.xls&#39;
        )

        self.path_to_geo_file = path_to_geo_file

        self.CODES_TO_IMPUTE = CODES_TO_IMPUTE_BEA.copy()

    def load_data(self):
        &#34;&#34;&#34;
        This class method is used to load and clean the data from the BEA. It relies on the data file paths, saved as
        class attributes when the instantiation function is called. Preprocessing steps are detailed in comments below.
        &#34;&#34;&#34;

        # We load the data from the appropriate Excel file
        bea = pd.read_excel(self.path_to_bea, sheet_name=&#39;Table II.E 2&#39;)

        # We rename columns, the following column names being used throughout the code
        bea.columns = [
            &#39;AFFILIATE_COUNTRY_NAME&#39;, &#39;TOTAL&#39;, &#39;TOTAL_US&#39;, &#39;TOTAL_US_RELATED&#39;, &#39;TOTAL_US_UNRELATED&#39;, &#39;TOTAL_FOREIGN&#39;,
            &#39;TOTAL_AFFILIATE_COUNTRY&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_RELATED&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_UNRELATED&#39;,
            &#39;TOTAL_OTHER_COUNTRY&#39;, &#39;TOTAL_OTHER_COUNTRY_RELATED&#39;, &#39;TOTAL_OTHER_COUNTRY_UNRELATED&#39;
        ]

        # We only keep relevant rows
        bea = bea.loc[8:].copy()

        bea = bea[~(bea.isnull().sum(axis=1) &gt;= 11)].copy()

        bea = bea.iloc[:-2].copy()

        bea = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] != &#39;Latin America and Other Western Hemisphere&#39;].copy()

        # We re-index the DataFrame after having filtered out inappropriate rows
        bea.reset_index(inplace=True, drop=True)

        # Due to the organisation of the Excel file, the DataFrame contains rows that only display the name of the con-
        # tinent associated with countries below; we want to eliminate these rows and reconstitute a &#34;one-block&#34; dataset
        continent_names = [
            &#39;Europe&#39;,
            &#39;South America&#39;,
            &#39;Central America&#39;,
            &#39;Other Western Hemisphere&#39;,
            &#39;Africa&#39;,
            &#39;Middle East&#39;,
            &#39;Asia and Pacific&#39;,
        ]

        # We fetch the list of the indices of these rows
        total_indices = list(
            bea[
                bea[&#39;AFFILIATE_COUNTRY_NAME&#39;].isin(continent_names)
            ].index
        )

        # We will store the sub-DataFrames associated with each continent in a dedicated dictionary
        continent_extracts = {}

        for i, continent_name in enumerate(continent_names):
            if i + 1 &lt; len(total_indices):
                continent_df = bea.loc[total_indices[i]:total_indices[i + 1] - 1].copy()

            else:
                continent_df = bea.loc[total_indices[i]:bea.index[-1]].copy()

            # In each sub-DataFrame, we rename the &#34;Other&#34; row as &#34;Other [+ CONTINENT NAME]&#34;
            continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] = continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;].map(
                lambda country_name: country_name if country_name != &#39;Other&#39; else &#39;Other &#39; + continent_name
            )

            continent_df = continent_df[continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] != continent_name].copy()

            continent_extracts[continent_name] = continent_df.copy()

        # The Canada row is outside any continent block
        bea_cleaned = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] == &#39;Canada&#39;].copy()

        # Upon it, we stack the different continent blocks to obtain one &#34;continuous&#34; dataset
        for continent_extract in continent_extracts.values():
            bea_cleaned = pd.concat([bea_cleaned, continent_extract], axis=0)

        # We eventually reformat missing values
        for column in bea_cleaned.columns[1:]:
            bea_cleaned[column] = bea_cleaned[column].map(
                lambda x: np.nan if x == &#39;(D)&#39; else x
            )

        return bea_cleaned.reset_index(drop=True)

    def load_data_with_geo_codes(self):
        &#34;&#34;&#34;
        This class method is used to add geographical ISO codes to the raw dataset, loaded with the &#34;load_data&#34; method.
        It relies on the &#34;impute_missing_codes&#34; function defined in utils.py.
        &#34;&#34;&#34;
        bea = self.load_data()

        geographies = pd.read_csv(self.path_to_geo_file)

        # We merge the DataFrame containing raw BEA data with the one containing the ISO code correspondences
        merged_df = bea.merge(
            geographies,
            how=&#39;left&#39;,
            left_on=&#39;AFFILIATE_COUNTRY_NAME&#39;, right_on=&#39;NAME&#39;
        )

        # We add missing codes
        for column in [&#39;NAME&#39;, &#39;CODE&#39;, &#39;CONTINENT_NAME&#39;, &#39;CONTINENT_CODE&#39;]:
            merged_df[column] = merged_df.apply(
                lambda row: impute_missing_codes(
                    row=row,
                    column=column,
                    codes_to_impute=self.CODES_TO_IMPUTE
                ),
                axis=1
            )

        # We don&#39;t consider &#34;Other&#34; aggregates as they are not the same as in the IRS data
        merged_df = merged_df[~merged_df[&#39;CODE&#39;].isnull()].copy()
        merged_df = merged_df[merged_df[&#39;CODE&#39;].map(len) &lt;= 3].copy()

        return merged_df.copy()

    def load_final_data(self):
        &#34;&#34;&#34;
        This class method allows to load the fully preprocessed BEA data. Relying on the &#34;load_data_with_geo_codes&#34; me-
        thod, continent names and codes are limited to 4 pairs, corresponding respectively to Europe, Africa, America
        (North and South) and Asia-Pacific (gathering Asia and Oceania).
        &#34;&#34;&#34;
        bea = self.load_data_with_geo_codes()

        bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
            lambda x: &#39;AMR&#39; if x in [&#39;SAMR&#39;, &#39;NAMR&#39;] else x
        )

        bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
            lambda x: &#39;America&#39; if x in [&#39;South America&#39;, &#39;North America&#39;] else x
        )

        bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
            lambda x: &#39;APAC&#39; if x in [&#39;ASIA&#39;, &#39;OCN&#39;] or x is None else x
        )

        bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
            lambda x: &#39;Asia-Pacific&#39; if x in [&#39;Asia&#39;, &#39;Oceania&#39;] or x is None else x
        )

        return bea.copy()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="destination_based_sales.bea.BEADataPreprocessor"><code class="flex name class">
<span>class <span class="ident">BEADataPreprocessor</span></span>
<span>(</span><span>year, path_to_dir='/Users/Paul-Emmanuel/Desktop/destination_based_sales/destination_based_sales', path_to_geo_file='/Users/Paul-Emmanuel/Desktop/destination_based_sales/destination_based_sales/data/geographies.csv')</span>
</code></dt>
<dd>
<div class="desc"><p>The instructions allowing to load and preprocess BEA data are organised in a Python class, BEADataPreprocessor.</p>
<p>This is the instantiation function for this class. It requires several arguments:</p>
<ul>
<li>the year to consider (for now, one of 2016, 2017 or 2018);</li>
<li>the path to the directory where this Python file is located, to retrieve the appropriate data file;</li>
<li>the path to the "geographies.csv" file, used for instance to complement BEA data with country codes.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BEADataPreprocessor:

    def __init__(
        self,
        year,
        path_to_dir=path_to_dir,
        path_to_geo_file=path_to_geographies
    ):
        &#34;&#34;&#34;
        The instructions allowing to load and preprocess BEA data are organised in a Python class, BEADataPreprocessor.

        This is the instantiation function for this class. It requires several arguments:

        - the year to consider (for now, one of 2016, 2017 or 2018);
        - the path to the directory where this Python file is located, to retrieve the appropriate data file;
        - the path to the &#34;geographies.csv&#34; file, used for instance to complement BEA data with country codes.
        &#34;&#34;&#34;
        self.year = year

        # We construct the path to the relevant data file, which depends on the year considered
        self.path_to_bea = os.path.join(
            path_to_dir,
            &#39;data&#39;,
            str(year),
            &#39;Part-II-E1-E17.xls&#39;
        )

        self.path_to_geo_file = path_to_geo_file

        self.CODES_TO_IMPUTE = CODES_TO_IMPUTE_BEA.copy()

    def load_data(self):
        &#34;&#34;&#34;
        This class method is used to load and clean the data from the BEA. It relies on the data file paths, saved as
        class attributes when the instantiation function is called. Preprocessing steps are detailed in comments below.
        &#34;&#34;&#34;

        # We load the data from the appropriate Excel file
        bea = pd.read_excel(self.path_to_bea, sheet_name=&#39;Table II.E 2&#39;)

        # We rename columns, the following column names being used throughout the code
        bea.columns = [
            &#39;AFFILIATE_COUNTRY_NAME&#39;, &#39;TOTAL&#39;, &#39;TOTAL_US&#39;, &#39;TOTAL_US_RELATED&#39;, &#39;TOTAL_US_UNRELATED&#39;, &#39;TOTAL_FOREIGN&#39;,
            &#39;TOTAL_AFFILIATE_COUNTRY&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_RELATED&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_UNRELATED&#39;,
            &#39;TOTAL_OTHER_COUNTRY&#39;, &#39;TOTAL_OTHER_COUNTRY_RELATED&#39;, &#39;TOTAL_OTHER_COUNTRY_UNRELATED&#39;
        ]

        # We only keep relevant rows
        bea = bea.loc[8:].copy()

        bea = bea[~(bea.isnull().sum(axis=1) &gt;= 11)].copy()

        bea = bea.iloc[:-2].copy()

        bea = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] != &#39;Latin America and Other Western Hemisphere&#39;].copy()

        # We re-index the DataFrame after having filtered out inappropriate rows
        bea.reset_index(inplace=True, drop=True)

        # Due to the organisation of the Excel file, the DataFrame contains rows that only display the name of the con-
        # tinent associated with countries below; we want to eliminate these rows and reconstitute a &#34;one-block&#34; dataset
        continent_names = [
            &#39;Europe&#39;,
            &#39;South America&#39;,
            &#39;Central America&#39;,
            &#39;Other Western Hemisphere&#39;,
            &#39;Africa&#39;,
            &#39;Middle East&#39;,
            &#39;Asia and Pacific&#39;,
        ]

        # We fetch the list of the indices of these rows
        total_indices = list(
            bea[
                bea[&#39;AFFILIATE_COUNTRY_NAME&#39;].isin(continent_names)
            ].index
        )

        # We will store the sub-DataFrames associated with each continent in a dedicated dictionary
        continent_extracts = {}

        for i, continent_name in enumerate(continent_names):
            if i + 1 &lt; len(total_indices):
                continent_df = bea.loc[total_indices[i]:total_indices[i + 1] - 1].copy()

            else:
                continent_df = bea.loc[total_indices[i]:bea.index[-1]].copy()

            # In each sub-DataFrame, we rename the &#34;Other&#34; row as &#34;Other [+ CONTINENT NAME]&#34;
            continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] = continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;].map(
                lambda country_name: country_name if country_name != &#39;Other&#39; else &#39;Other &#39; + continent_name
            )

            continent_df = continent_df[continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] != continent_name].copy()

            continent_extracts[continent_name] = continent_df.copy()

        # The Canada row is outside any continent block
        bea_cleaned = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] == &#39;Canada&#39;].copy()

        # Upon it, we stack the different continent blocks to obtain one &#34;continuous&#34; dataset
        for continent_extract in continent_extracts.values():
            bea_cleaned = pd.concat([bea_cleaned, continent_extract], axis=0)

        # We eventually reformat missing values
        for column in bea_cleaned.columns[1:]:
            bea_cleaned[column] = bea_cleaned[column].map(
                lambda x: np.nan if x == &#39;(D)&#39; else x
            )

        return bea_cleaned.reset_index(drop=True)

    def load_data_with_geo_codes(self):
        &#34;&#34;&#34;
        This class method is used to add geographical ISO codes to the raw dataset, loaded with the &#34;load_data&#34; method.
        It relies on the &#34;impute_missing_codes&#34; function defined in utils.py.
        &#34;&#34;&#34;
        bea = self.load_data()

        geographies = pd.read_csv(self.path_to_geo_file)

        # We merge the DataFrame containing raw BEA data with the one containing the ISO code correspondences
        merged_df = bea.merge(
            geographies,
            how=&#39;left&#39;,
            left_on=&#39;AFFILIATE_COUNTRY_NAME&#39;, right_on=&#39;NAME&#39;
        )

        # We add missing codes
        for column in [&#39;NAME&#39;, &#39;CODE&#39;, &#39;CONTINENT_NAME&#39;, &#39;CONTINENT_CODE&#39;]:
            merged_df[column] = merged_df.apply(
                lambda row: impute_missing_codes(
                    row=row,
                    column=column,
                    codes_to_impute=self.CODES_TO_IMPUTE
                ),
                axis=1
            )

        # We don&#39;t consider &#34;Other&#34; aggregates as they are not the same as in the IRS data
        merged_df = merged_df[~merged_df[&#39;CODE&#39;].isnull()].copy()
        merged_df = merged_df[merged_df[&#39;CODE&#39;].map(len) &lt;= 3].copy()

        return merged_df.copy()

    def load_final_data(self):
        &#34;&#34;&#34;
        This class method allows to load the fully preprocessed BEA data. Relying on the &#34;load_data_with_geo_codes&#34; me-
        thod, continent names and codes are limited to 4 pairs, corresponding respectively to Europe, Africa, America
        (North and South) and Asia-Pacific (gathering Asia and Oceania).
        &#34;&#34;&#34;
        bea = self.load_data_with_geo_codes()

        bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
            lambda x: &#39;AMR&#39; if x in [&#39;SAMR&#39;, &#39;NAMR&#39;] else x
        )

        bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
            lambda x: &#39;America&#39; if x in [&#39;South America&#39;, &#39;North America&#39;] else x
        )

        bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
            lambda x: &#39;APAC&#39; if x in [&#39;ASIA&#39;, &#39;OCN&#39;] or x is None else x
        )

        bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
            lambda x: &#39;Asia-Pacific&#39; if x in [&#39;Asia&#39;, &#39;Oceania&#39;] or x is None else x
        )

        return bea.copy()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="destination_based_sales.bea.BEADataPreprocessor.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This class method is used to load and clean the data from the BEA. It relies on the data file paths, saved as
class attributes when the instantiation function is called. Preprocessing steps are detailed in comments below.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(self):
    &#34;&#34;&#34;
    This class method is used to load and clean the data from the BEA. It relies on the data file paths, saved as
    class attributes when the instantiation function is called. Preprocessing steps are detailed in comments below.
    &#34;&#34;&#34;

    # We load the data from the appropriate Excel file
    bea = pd.read_excel(self.path_to_bea, sheet_name=&#39;Table II.E 2&#39;)

    # We rename columns, the following column names being used throughout the code
    bea.columns = [
        &#39;AFFILIATE_COUNTRY_NAME&#39;, &#39;TOTAL&#39;, &#39;TOTAL_US&#39;, &#39;TOTAL_US_RELATED&#39;, &#39;TOTAL_US_UNRELATED&#39;, &#39;TOTAL_FOREIGN&#39;,
        &#39;TOTAL_AFFILIATE_COUNTRY&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_RELATED&#39;, &#39;TOTAL_AFFILIATE_COUNTRY_UNRELATED&#39;,
        &#39;TOTAL_OTHER_COUNTRY&#39;, &#39;TOTAL_OTHER_COUNTRY_RELATED&#39;, &#39;TOTAL_OTHER_COUNTRY_UNRELATED&#39;
    ]

    # We only keep relevant rows
    bea = bea.loc[8:].copy()

    bea = bea[~(bea.isnull().sum(axis=1) &gt;= 11)].copy()

    bea = bea.iloc[:-2].copy()

    bea = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] != &#39;Latin America and Other Western Hemisphere&#39;].copy()

    # We re-index the DataFrame after having filtered out inappropriate rows
    bea.reset_index(inplace=True, drop=True)

    # Due to the organisation of the Excel file, the DataFrame contains rows that only display the name of the con-
    # tinent associated with countries below; we want to eliminate these rows and reconstitute a &#34;one-block&#34; dataset
    continent_names = [
        &#39;Europe&#39;,
        &#39;South America&#39;,
        &#39;Central America&#39;,
        &#39;Other Western Hemisphere&#39;,
        &#39;Africa&#39;,
        &#39;Middle East&#39;,
        &#39;Asia and Pacific&#39;,
    ]

    # We fetch the list of the indices of these rows
    total_indices = list(
        bea[
            bea[&#39;AFFILIATE_COUNTRY_NAME&#39;].isin(continent_names)
        ].index
    )

    # We will store the sub-DataFrames associated with each continent in a dedicated dictionary
    continent_extracts = {}

    for i, continent_name in enumerate(continent_names):
        if i + 1 &lt; len(total_indices):
            continent_df = bea.loc[total_indices[i]:total_indices[i + 1] - 1].copy()

        else:
            continent_df = bea.loc[total_indices[i]:bea.index[-1]].copy()

        # In each sub-DataFrame, we rename the &#34;Other&#34; row as &#34;Other [+ CONTINENT NAME]&#34;
        continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] = continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;].map(
            lambda country_name: country_name if country_name != &#39;Other&#39; else &#39;Other &#39; + continent_name
        )

        continent_df = continent_df[continent_df[&#39;AFFILIATE_COUNTRY_NAME&#39;] != continent_name].copy()

        continent_extracts[continent_name] = continent_df.copy()

    # The Canada row is outside any continent block
    bea_cleaned = bea[bea[&#39;AFFILIATE_COUNTRY_NAME&#39;] == &#39;Canada&#39;].copy()

    # Upon it, we stack the different continent blocks to obtain one &#34;continuous&#34; dataset
    for continent_extract in continent_extracts.values():
        bea_cleaned = pd.concat([bea_cleaned, continent_extract], axis=0)

    # We eventually reformat missing values
    for column in bea_cleaned.columns[1:]:
        bea_cleaned[column] = bea_cleaned[column].map(
            lambda x: np.nan if x == &#39;(D)&#39; else x
        )

    return bea_cleaned.reset_index(drop=True)</code></pre>
</details>
</dd>
<dt id="destination_based_sales.bea.BEADataPreprocessor.load_data_with_geo_codes"><code class="name flex">
<span>def <span class="ident">load_data_with_geo_codes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This class method is used to add geographical ISO codes to the raw dataset, loaded with the "load_data" method.
It relies on the "impute_missing_codes" function defined in utils.py.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data_with_geo_codes(self):
    &#34;&#34;&#34;
    This class method is used to add geographical ISO codes to the raw dataset, loaded with the &#34;load_data&#34; method.
    It relies on the &#34;impute_missing_codes&#34; function defined in utils.py.
    &#34;&#34;&#34;
    bea = self.load_data()

    geographies = pd.read_csv(self.path_to_geo_file)

    # We merge the DataFrame containing raw BEA data with the one containing the ISO code correspondences
    merged_df = bea.merge(
        geographies,
        how=&#39;left&#39;,
        left_on=&#39;AFFILIATE_COUNTRY_NAME&#39;, right_on=&#39;NAME&#39;
    )

    # We add missing codes
    for column in [&#39;NAME&#39;, &#39;CODE&#39;, &#39;CONTINENT_NAME&#39;, &#39;CONTINENT_CODE&#39;]:
        merged_df[column] = merged_df.apply(
            lambda row: impute_missing_codes(
                row=row,
                column=column,
                codes_to_impute=self.CODES_TO_IMPUTE
            ),
            axis=1
        )

    # We don&#39;t consider &#34;Other&#34; aggregates as they are not the same as in the IRS data
    merged_df = merged_df[~merged_df[&#39;CODE&#39;].isnull()].copy()
    merged_df = merged_df[merged_df[&#39;CODE&#39;].map(len) &lt;= 3].copy()

    return merged_df.copy()</code></pre>
</details>
</dd>
<dt id="destination_based_sales.bea.BEADataPreprocessor.load_final_data"><code class="name flex">
<span>def <span class="ident">load_final_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This class method allows to load the fully preprocessed BEA data. Relying on the "load_data_with_geo_codes" me-
thod, continent names and codes are limited to 4 pairs, corresponding respectively to Europe, Africa, America
(North and South) and Asia-Pacific (gathering Asia and Oceania).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_final_data(self):
    &#34;&#34;&#34;
    This class method allows to load the fully preprocessed BEA data. Relying on the &#34;load_data_with_geo_codes&#34; me-
    thod, continent names and codes are limited to 4 pairs, corresponding respectively to Europe, Africa, America
    (North and South) and Asia-Pacific (gathering Asia and Oceania).
    &#34;&#34;&#34;
    bea = self.load_data_with_geo_codes()

    bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
        lambda x: &#39;AMR&#39; if x in [&#39;SAMR&#39;, &#39;NAMR&#39;] else x
    )

    bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
        lambda x: &#39;America&#39; if x in [&#39;South America&#39;, &#39;North America&#39;] else x
    )

    bea[&#39;CONTINENT_CODE&#39;] = bea[&#39;CONTINENT_CODE&#39;].map(
        lambda x: &#39;APAC&#39; if x in [&#39;ASIA&#39;, &#39;OCN&#39;] or x is None else x
    )

    bea[&#39;CONTINENT_NAME&#39;] = bea[&#39;CONTINENT_NAME&#39;].map(
        lambda x: &#39;Asia-Pacific&#39; if x in [&#39;Asia&#39;, &#39;Oceania&#39;] or x is None else x
    )

    return bea.copy()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="destination_based_sales" href="index.html">destination_based_sales</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="destination_based_sales.bea.BEADataPreprocessor" href="#destination_based_sales.bea.BEADataPreprocessor">BEADataPreprocessor</a></code></h4>
<ul class="">
<li><code><a title="destination_based_sales.bea.BEADataPreprocessor.load_data" href="#destination_based_sales.bea.BEADataPreprocessor.load_data">load_data</a></code></li>
<li><code><a title="destination_based_sales.bea.BEADataPreprocessor.load_data_with_geo_codes" href="#destination_based_sales.bea.BEADataPreprocessor.load_data_with_geo_codes">load_data_with_geo_codes</a></code></li>
<li><code><a title="destination_based_sales.bea.BEADataPreprocessor.load_final_data" href="#destination_based_sales.bea.BEADataPreprocessor.load_final_data">load_final_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>